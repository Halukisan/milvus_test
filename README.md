# 项目介绍
## 数据集
### data_base/knowledge_db
该目录下存放着用于向量化存储的数据，包含md，word，pdf等文件。

## 搜索
### text_search_pic
使用文字搜索图片，使用了toWhere，向量化使用的是openai的clip-vit-base-patch16
### data_maker
该目录下是通用文件处理代码，可以一次性获取所有的md文件或者pdf文件并读取内容进行格式化。
### csdn_milvus
该目录下存放着最基础的向量数据库的构建和数据处理，如果不了解milvus，先看这个文件下的代码。
### milvus_create 
该目录下存放着结合构建milvus和rag的代码
### video_url_test
该目录下存放的代码解决了如下问题

1. 想用rag实现一个视频推送功能，用户提问，然后大模型给出文字回答和相关文字解释视频的播放地址，在灌库之前应该怎么处理，直接让播放地址和文字一起，播放地址可能就会被切断。就是切割的时候会把视频的url 切成两半，然后输出的url地址打不开。
2. milvus的结构设计，有利于后期的优化处理
3. 快速便捷的批量读取各种类型文件数据并且自动获取其中的url并结合文字描述，合理地存储到milvus中
4. 用户询问一些专业知识，可以根据milvus里面获取到数据并且返回给我相应的url，但是，我如果问你好，或者哇哦等普通词语，他也会随便给我返回url。解决方案：根据召回分数进行筛选数据：这种闲聊召回的数据分数都不高，设定一个min score，召回的top k中的每条数据至少超过这个min score，才能融合到prompt中
5. gradio编写的极为简单的页面

后期扩展内容

1. 优化页面展示（url和文字分开的更加优美）
2. 增加functionCalling功能，优化数据的获取与展示
3. 待定......


## 两种聚类方法
### milvus_plus

参考推荐系统fun-rec中的余弦相似度分类数据得到的如下思路：

* 基于k-mean聚合后得到中心标准向量
* 自动读取文档内容
* 责任链模式进行匹配
* 分块存储数据，提高查询效率

使用步骤：
    首先init.py文件中，计算中心标准向量，这里的文件名称需要规范，因为下面的代码是写死的，这个文件要单独执行，主要就是计算中心标准向量，其他的都不做。对于这个示例代码，我需要存放到文件夹中的md文件名称需要是java、mysql、redis、web。

    此时我们获得到了中心标准向量，然后就可以进行下面的操作了，在create.py文件中，可以进行如下操作。读取所有你需要进行向量化存储的文件（这里不用规范名称了，只要是md文件都行），进入责任链，然后存储milvus中。
    至此，分块存储完成（详细请看代码，有注释）
    
    start.py中包含启动函数，运行之前，请手动把中心标准向量复制到里面，（此处不宜设置为自动处理，手动更好）。
    对于用户问题，同样的流程，向量化后进责任链，确定数据所处分块的位置后，取前五条最相似的数据进行相似度匹配，大于预设的值的可以作为参考数据，写入prompt中。


优化：
    分块存储后，模型的回答可以做优化，比如加入CoT，提高模型回答准确度。

### milvus_HDBSCAN
HDBSCAN 是一种基于密度的聚类算法，它能够处理噪声和任意形状的聚类。该算法通过计算数据点之间的距离来确定聚类，并能够自动确定聚类的数量。

我们使用 BGE-M3 嵌入模型从新闻标题数据集中提取嵌入，利用 Milvus 计算嵌入之间的距离以帮助 HDBSCAN 进行聚类，然后使用 UMAP 方法将结果可视化以进行分析。
如果你的电脑没有nvida的GPU,建议在魔搭社区的notebookGPU环境下运行该项目


## Need to know
### 构建数据集要求
问题：噪声、重复、低质数据会污染知识库，导致检索到无关内容。
解决方案：
1. 清洗数据：去除HTML标签、特殊符号、乱码等噪声。
2. 去重：合并相似内容，避免冗余数据干扰检索。
3. 标准化：统一文本格式（如日期、单位）、大小写、标点符号。
4. 质量筛选：优先保留权威来源、高可信度的内容。
   
数据与场景的匹配性问题：知识库与应用场景偏离会导致检索失效。
解决方案：
1. 场景过滤：仅保留与目标任务相关的数据（例如医疗场景需剔除无关行业内容）。
2. 动态更新：定期增量更新数据，避免时效性内容过期。
3. 冷启动优化：初期可引入人工标注的高质量种子数据。

安全与合规风险问题：随意导入数据可能泄露敏感信息或引入偏见。
解决方案：
1. 敏感信息过滤：使用NER识别并脱敏（如身份证号、电话号码）。
2. 偏见检测：通过公平性评估工具（如Fairness Indicators）筛查歧视性内容。
3. 权限控制：对知识库分级访问，限制敏感数据检索权限。

还有以下注意事项：

文本分块（Chunking）需策略化问题：随意分块可能导致语义不完整，影响向量表示。
解决方案：
1. 按语义切分：使用句子边界检测、段落分割或基于语义相似度的算法（如BERT句间相似度）。
2. 动态调整块大小：根据数据特性调整（例如技术文档适合较长的块，对话数据适合短块）。
3. 重叠分块：相邻块保留部分重叠文本，避免关键信息被切分到边缘。

向量化模型的适配性问题：直接使用通用模型可能无法捕捉领域语义。
解决方案：
1. 领域微调：在领域数据上微调模型（如BERT、RoBERTa）以提升向量表征能力。
2. 多模态支持：若包含图表、代码等，需选择支持多模态的模型（如CLIP、CodeBERT）。
3. 轻量化部署：权衡精度与效率，可选择蒸馏后的模型（如MiniLM）。

索引结构与检索效率问题：海量数据未经优化会导致检索延迟。
解决方案：
1. 分层索引：对高频数据使用HNSW，长尾数据用IVF-PQ（Faiss或Milvus）。
2. 元数据过滤：为数据添加标签（如时间、类别），加速粗筛过程。
3. 分布式部署：按数据热度分片，结合缓存机制（如Redis）提升响应速度。

补充说明：向量知识库数据集也要是问答对？
将数据整理成问答对（QA Pair）形式是一种优化策略，而非必要步骤。但这种方式在特定场景下能显著提升检索和生成的效果。
以下是其核心原因和适用场景的分析：
1. 为什么问答对形式能优化RAG？
   （1）精准对齐用户查询意图问题：用户输入通常是自然语言问题（如“如何重置密码？”），而知识库若存储的是纯文本段落（如技术文档），检索时可能因语义差异导致匹配失败。问答对的优势：直接以“问题-答案”形式存储知识，检索时相似度计算更聚焦于“问题与问题”的匹配（Question-Question Similarity），而非“问题与段落”的匹配。例如，若知识库中存有QA对 Q: 如何重置密码？ → A: 进入设置页面，点击“忘记密码”...，当用户提问“密码忘了怎么办？”时，即使表述不同，向量模型也能捕捉到语义相似性。
   （2）降低生成模型的负担问题：若检索到的是长文本段落，生成模型（如GPT）需要从段落中提取关键信息并重组答案，可能导致信息冗余或遗漏。问答对的优势：答案部分已是对问题的直接回应，生成模型只需“改写”或“补充”答案，而非从头生成，降低幻觉风险。例如，QA对中的答案已结构化（如步骤列表），生成结果更规范。（3）提升检索效率与召回率问题：传统分块检索可能因文本块过长或过短导致关键信息丢失（如答案分散在多个段落）。问答对的优势：每个QA对是自包含的语义单元，检索时直接返回完整答案，减少上下文碎片化问题。可针对高频问题设计专用QA对，提高热门问题的响应速度和准确性。
2. 哪些场景适合问答对形式？
   （1）任务型对话系统适用场景：客服机器人、技术支持、医疗咨询等垂直领域。原因：用户需求明确，答案通常简短且结构化（如操作步骤、诊断建议）。案例：用户问：“如何退订会员？” → 直接匹配QA对中的答案：“登录账号→进入订阅管理→点击取消”。
   （2）FAQ（常见问题解答）库适用场景：产品帮助文档、政策解读等。原因：FAQ天然适合QA形式，直接覆盖高频问题。案例：知识库存储 Q: 保修期多久？ → A: 本产品保修期为2年。
   （3）知识密集型生成任务适用场景：需要精确引用事实的场景（如法律咨询、学术问答）。原因：QA对中的答案可作为“事实锚点”，减少生成模型的自由发挥。案例：用户问：“《民法典》规定离婚冷静期多久？” → 返回QA对中的法条原文。
问答对构建的注意事项并非所有数据都适合QA形式避免强制转换：叙述性文本（如小说、新闻）或开放域知识（如百科条目）更适合以段落或实体为中心存储。强行拆分为QA可能导致信息割裂（例如将“量子力学发展史”拆解为多个不连贯的问答）。

## 相关技术介绍

### Towhere

Towhee 是一个开源的 **多模态数据处理框架**，专注于高效生成非结构化数据（如文本、图像、音频、视频等）的向量表示（Embeddings），并支持构建端到端的 AI 流水线（Pipeline）。它旨在简化从原始数据到向量化表示再到实际应用（如搜索、推荐、问答系统）的开发流程，尤其适用于需要处理多模态数据的场景。

---

### **一、Towhee 的核心功能**
1. **多模态 Embedding 生成**  
   - 支持文本、图像、音频、视频等非结构化数据的向量化。
   - 内置丰富的预训练模型（如 BERT、CLIP、ViT、ResNet、Whisper 等），可直接调用。
   - 支持自定义模型集成，灵活适配业务需求。

2. **流水线（Pipeline）构建**  
   - 提供声明式 API，通过链式调用快速组合数据处理步骤（如数据加载、预处理、模型推理、后处理等）。
   - 示例：一个图像搜索流水线可以包含 `图像解码 → 特征提取 → 向量归一化 → 存储到向量数据库`。

3. **高性能与可扩展性**  
   - 支持批量处理（Batch Processing）和 GPU 加速。
   - 分布式计算能力，适合大规模数据处理。
   - 通过算子（Operator）机制，可灵活扩展新功能。

4. **与向量数据库无缝集成**  
   - 深度兼容 Milvus、Elasticsearch、FAISS 等向量数据库，简化数据存储与检索流程。

---

### **二、Towhee 的架构**
Towhee 的架构围绕 **Operator** 和 **Pipeline** 设计：
1. **Operator（算子）**  
   - 原子化数据处理单元，每个 Operator 完成单一任务（如 `image_decode`、`text_embedding`）。
   - 分为两类：
     - **Hub Operators**：官方预置的算子，开箱即用。
     - **Custom Operators**：用户自定义算子，支持 Python 编写。

2. **Pipeline（流水线）**  
   - 通过连接多个 Operator 构建端到端的数据处理流程。
   - 支持并行执行、条件分支等复杂逻辑。
   - 示例代码：
     ```python
     from towhee import pipe, ops

     image_search_pipeline = (
         pipe.input('image_path')
             .map('image_path', 'image', ops.image_decode())
             .map('image', 'embedding', ops.image_embedding(model_name='clip_vit_base_patch32'))
             .output('embedding')
     )
     ```

3. **执行引擎**  
   - 自动优化计算图（如算子融合、并行调度）。
   - 支持同步/异步执行模式。

---

### **三、应用场景**
1. **跨模态搜索**  
   - 如“以图搜图”、“以文搜图”、“语音搜索”等。
   - 示例：用 CLIP 模型将文本和图像映射到同一向量空间，实现跨模态检索。

2. **推荐系统**  
   - 生成用户和物品的 Embedding，计算相似度进行推荐。

3. **问答系统（QA）**  
   - 将问题和文档编码为向量，通过语义匹配找到最佳答案。

4. **内容理解与分类**  
   - 对视频、音频进行内容分析（如标签生成、情感分析）。

---

### **四、快速入门示例**
1. **安装 Towhee**
   ```bash
   pip install towhee
   ```

2. **生成文本 Embedding**
   ```python
   import towhee

   text_embedding = (
       towhee.text('Hello, Towhee!')
           .text_embedding.transformers(model_name='bert-base-uncased')
           .to_list()[0]
   )
   print(text_embedding.shape)  # 输出: (768,)
   ```

3. **构建图像搜索流水线**
   ```python
   from towhee import pipe, ops

   pipeline = (
       pipe.input('url')
           .map('url', 'image', ops.image_decode())
           .map('image', 'vec', ops.image_embedding.timm(model_name='resnet50'))
           .output('vec')
   )

   result = pipeline('https://example.com/image.jpg')
   ```

---

### **五、Towhee 的优势与特点**
- **多模态统一接口**：一套 API 处理文本、图像、视频等多种数据类型。
- **开箱即用**：预集成 100+ 模型和算子，覆盖主流算法（如 OpenAI CLIP、Sentence-BERT）。
- **灵活性**：支持自定义算子与流水线，适配私有模型和业务逻辑。
- **生产就绪**：支持微服务部署（如 Docker、Kubernetes），提供 RESTful API 封装。

---

### **六、与其他工具的对比**
| 工具                            | 定位               | 特点                    |
| ----------------------------- | ---------------- | --------------------- |
| **Towhee**                    | 多模态 Embedding 框架 | 端到端流水线、多模态支持          |
| **Hugging Face Transformers** | 单模态模型库           | 文本/图像模型丰富，但需自行构建流程    |
| **Milvus**                    | 向量数据库            | 专注向量存储与检索，与 Towhee 互补 |
| **LangChain**                 | 大语言模型应用开发框架      | 侧重文本任务链式调用，多模态能力弱     |

---

### **七、社区与资源**
- **GitHub**: [https://github.com/towhee-io/towhee](https://github.com/towhee-io/towhee)
- **文档**: [https://towhee.io](https://towhee.io)
- **案例教程**: 提供跨模态搜索、推荐系统等实战示例。

---

### **总结**
Towhee 通过简化多模态数据处理流程，降低了 AI 应用的开发门槛。无论是快速验证原型还是部署生产系统，它都能提供高效灵活的解决方案。如果你需要处理复杂的非结构化数据并生成高质量的 Embedding，Towhee 是一个值得尝试的工具。