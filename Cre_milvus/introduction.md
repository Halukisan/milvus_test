## Introduction
为什么要做这个,对于RAG的检索数据和性能,不一定要按照宁可获取的数据多,也不能少的原则,而是要达到一个性能和数据量之间的平衡。通过聚类算法，将相似的数据聚在一起，从而提高检索性能。除此之外,也是想做一个方便的接口,只需要输入参数,即可获取一个高性能(我自己认为的,目前没有安排分布式....)的向量数据库方案。
### 基础功能
可快速接入项目的Milvus向量数据库方案，:done
提供CPU和GPU索引选择，:done
登录加密、:done
数据聚类分块选择，done
内存副本以提高吞吐，:done
多模态数据（文本、文件、图片）自动化处理和存储。:done

## 优化
1. 加入ES进行多路召回
2. 加入缓存（Redis），优化检索性能。
3. 结合基于k8s的日志监控
4. 对结果重排序，将相似的内容分到一起
5. 分布式？内存分片？
6. 文件处理多线程。done
7. 处理失败后重试机制
8. 数据质量评估并标记，将低质量的数据分为其他的collection中


### 关于两种聚类算法
**K-Means**
k-means是一种基于划分的聚类算法，主要思想是把数据划分到k个簇，每个簇都有中心点。
该算法速度快，形成的簇近似于球形，适合于大量的、简单的、规则的数据集。
1. 用户选择簇的数量
2. 随机选择K个点作为中心点
3. 将每个样本分配到距离最近的质心所在的簇
4. 对每个簇重新计算所有成员的平均值作为新的质心
5. 重复步骤3和4，直到质心不在变化或者到达最大的迭代次数
6. 
**原理：** k-means 的核心思想是，把数据分成 k 个群组（也叫簇），每个群组都有一个“中心点”（也叫质心），目标是让每个点都尽可能靠近自己群组的中心点。简单来说，就是“物以类聚，人以群分”。

**步骤：**

选中心： 先随机选 k 个点，把它们当成初始的中心点。

分堆： 把每个数据点都分到离它最近的中心点所在的群组。

算中心： 重新计算每个群组的中心点（通常是这个群组里所有点的平均值）。

重复： 重复 “分堆” 和 “算中心” 这两步，直到中心点不再怎么变化，或者达到你设定的最大循环次数。

**HDBSCAN**
HDBSCAN聚类是一种基于密度的聚类算法。
该算法速度慢，形成的簇是任意形状的，但适合于复杂的、含噪声的数据集。
1. 通过最小样本数和最小簇大小来估计每个点的密度，也就是看这个点周围有多少邻居
2. 基于点之间的距离和密度关系构建最小生成树，代表两个点的距离
3. 通过不断的切割形成不同密度的簇，也就是说切割哪些距离很长的边（距离很远的点），哪些怎么都连接不上的点就是噪声点
4. HDBSCAN算法可以自动判断分几组，还会自动判断哪些组最稳定

**核心概念：**

核心距离： 对于每个点，找到包含至少 minPts 个点的最小半径，这个半径就是该点的核心距离。

可达距离： 点 A 到点 B 的可达距离是：点 B 的核心距离 和 A 到 B 的实际距离，两者取最大值。

互达性图： 基于可达距离构建的图，距离越小，连接越紧密。

簇的提取： 通过在互达性图上进行聚类，提取簇。

**步骤（简化版）：**

算密度： 评估每个点周围的密度。

建树： 构建一个层次聚类树，把密度相近的点放在一起。

剪枝： 根据密度和连通性，对聚类树进行剪枝，去除噪声和不稳定的簇。

提取簇： 从剪枝后的树中提取最终的簇。

请理解聚类的概念,可以参考哔哩哔哩中zilliz的讲解视频,在二维平面上,运用聚类算法可以更好的将相似的数据聚在一起，从而提高检索性能。
### 关于聚类的时机
下面有三种使用聚类算法的时机：
1. 如果检索性能是首要目标：
   * 在数据存储时进行聚类，并将聚类标签存储到数据库中。
   * 检索时直接利用聚类标签快速定位相关数据
2. 如果数据动态变化比较频繁：
   * 在检索时对召回的数据进行分类，动态分析数据分布
3. 如果需要离线数据分析
   * 定期对数据进行聚类，用于分析或推荐系统


> 目前采用方案一:性能作为首选目标

### 关于重排序
有四种方案
1. 基于距离的重排序
   * 在二维平面中,每个聚类都有聚类中心向量,将每个聚类的结果按照与中心向量的距离进行重排序,优先返回距离比较近的结果
2. 基于聚类大小的重排序
   * 按照聚类的大小(每个聚类中包含的结果数量)从大到小排序,优先返回较大的聚类
3. 基于聚类中心的重排序
   * 计算每个聚类的中心点,按质心与查询向量的距离从小到大排序
4. 基于特定业务的重排序
   * 你自己怎么想的就怎么做

