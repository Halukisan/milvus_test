{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "从 https://www.kaggle.com/datasets/dylanjcastillo/news-headlines-2024/ 下载新闻数据集，news_data_dedup.csv 并将其放入当前目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:27:56.715846Z",
     "iopub.status.busy": "2025-04-02T07:27:56.715575Z",
     "iopub.status.idle": "2025-04-02T07:28:19.571427Z",
     "shell.execute_reply": "2025-04-02T07:28:19.570863Z",
     "shell.execute_reply.started": "2025-04-02T07:27:56.715830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"pymilvus[model]\"\n",
    "!pip install hdbscan\n",
    "!pip install plotly\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取 Embeddings 至 Milvus\n",
    "我们将使用 Milvus 创建一个 Collections，并使用 BGE-M3 模型提取密集嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-04-02T07:50:05.150469Z",
     "iopub.status.busy": "2025-04-02T07:50:05.150168Z",
     "iopub.status.idle": "2025-04-02T07:53:43.032601Z",
     "shell.execute_reply": "2025-04-02T07:53:43.032142Z",
     "shell.execute_reply.started": "2025-04-02T07:50:05.150451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "from pymilvus import FieldSchema, Collection, connections, CollectionSchema, DataType\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "df = pd.read_csv(\"news_data_dedup.csv\")\n",
    "\n",
    "# 使用列表推导式，将dataFame的title和description列拼接成一个列表，每个字符串由标题和描述组成\n",
    "docs = [\n",
    "    f\"{title}\\n{description}\" for title, description in zip(df.title, df.description)\n",
    "]\n",
    "\n",
    "# 使用modelscope下载模型\n",
    "model_path = snapshot_download('BAAI/bge-m3', revision='master')\n",
    "# 然后使用本地路径加载模型\n",
    "ef = BGEM3EmbeddingFunction(\n",
    "    model_name=model_path,  # 使用本地模型路径\n",
    "    device='cpu', # 指定设备为cpu\n",
    "    use_fp16=False # 是否使用fp16精度\n",
    ")\n",
    "\n",
    "embeddings = ef(docs)[\"dense\"] # ef为嵌入函数，docs为输入数据，dense键对应的值为嵌入向量\n",
    "\n",
    "connections.connect(uri=\"milvus.db\") # 数据存入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 结构\n",
    "fields = [\n",
    "    FieldSchema(\n",
    "        name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True\n",
    "    ), \n",
    "    FieldSchema(\n",
    "        name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=1024\n",
    "    ), \n",
    "    FieldSchema(\n",
    "        name=\"text\", dtype=DataType.VARCHAR, max_length=65535\n",
    "    ), \n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, description=\"Embedding collection\")\n",
    "\n",
    "collection = Collection(name=\"news_data\", schema=schema)\n",
    "\n",
    "for doc, embedding in zip(docs, embeddings):\n",
    "    collection.insert({\"text\": doc, \"embedding\": embedding})\n",
    "    print(doc)\n",
    "\n",
    "index_params = {\"index_type\": \"FLAT\", \"metric_type\": \"L2\", \"params\": {}}\n",
    "\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "collection.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为 HDBSCAN 构建距离矩阵\n",
    "HDBSCAN 需要计算点与点之间的距离来进行聚类，计算量很大。由于远处的点对聚类分配的影响较小，我们可以通过计算前 k 个近邻来提高效率。在本例中，我们使用的是 FLAT 索引，但对于大规模数据集，Milvus 支持更高级的索引方法来加速搜索过程。 首先，我们需要获取一个迭代器来迭代之前创建的 Milvus Collections。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:55:46.834233Z",
     "iopub.status.busy": "2025-04-02T07:55:46.833893Z",
     "iopub.status.idle": "2025-04-02T07:55:55.468938Z",
     "shell.execute_reply": "2025-04-02T07:55:55.468339Z",
     "shell.execute_reply.started": "2025-04-02T07:55:46.834215Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 15:55:55,466 [WARNING][__setup_ts_by_request]: failed to get mvccTs from milvus server, use client-side ts instead (iterator.py:258)\n"
     ]
    }
   ],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from umap import UMAP\n",
    "from pymilvus import Collection\n",
    "\n",
    "collection = Collection(name=\"news_data\")\n",
    "collection.load()\n",
    "\n",
    "# 查询迭代器\n",
    "# batch_size为每次查询的条数\n",
    "# expr为查询条件\n",
    "# output_fields为输出的字段\n",
    "iterator = collection.query_iterator(\n",
    "    batch_size=10, expr=\"id > 0\", output_fields=[\"id\", \"embedding\"]\n",
    ")\n",
    "\n",
    "# L2表示欧氏距离 作为相似性度量方法\n",
    "# nprobe表示查询时的探测数 决定了搜索的精度和速度\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}  \n",
    "ids = []\n",
    "dist = {}\n",
    "\n",
    "embeddings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类操作\n",
    "下面我们来演示如何使用HDBScan进行聚类操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:55:58.823984Z",
     "iopub.status.busy": "2025-04-02T07:55:58.823318Z",
     "iopub.status.idle": "2025-04-02T07:56:00.619188Z",
     "shell.execute_reply": "2025-04-02T07:56:00.618739Z",
     "shell.execute_reply.started": "2025-04-02T07:55:58.823959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # 提取每条数据的id和embedding，id存入ids列表中\n",
    "    batch = iterator.next()\n",
    "    batch_ids = [data[\"id\"] for data in batch]\n",
    "    ids.extend(batch_ids)\n",
    "    # 将每条数据的embedding存入embeddings列表中 \n",
    "    query_vectors = [data[\"embedding\"] for data in batch]\n",
    "    embeddings.extend(query_vectors)\n",
    "    # 现在获取到了ids列表和embeddings列表，我们可以使用hdbscan进行聚类操作了\n",
    "\n",
    "\n",
    "    # 使用milvus的搜索\n",
    "    results = collection.search(\n",
    "        data=query_vectors,\n",
    "        limit=50,\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        output_fields=[\"id\"],\n",
    "    )\n",
    "    # 搜索结果存入dist字典中，键为batch_id，值为一个列表，列表中每个元素为一个元组，元组的第一个元素为id，第二个元素为距离（与该向量最相似的ID及其距离）\n",
    "    for i, batch_id in enumerate(batch_ids):\n",
    "        dist[batch_id] = []\n",
    "        for result in results[i]:\n",
    "            dist[batch_id].append((result.id, result.distance))\n",
    "\n",
    "    if len(batch) == 0:\n",
    "        break\n",
    "\n",
    "# 构建距离矩阵\n",
    "# ids2index是一个字典，键为id，值为该id在ids列表中的索引\n",
    "ids2index = {}\n",
    "\n",
    "for id in dist:\n",
    "    ids2index[id] = len(ids2index)\n",
    "\n",
    "# dist_metric是二维距离矩阵\n",
    "dist_metric = np.full((len(ids), len(ids)), np.inf, dtype=np.float64)\n",
    "\n",
    "# 根据字典中的搜索结果填充距离矩阵，表示meita_id和batch_id之间的距离\n",
    "for id in dist:\n",
    "    for result in dist[id]:\n",
    "        dist_metric[ids2index[id]][ids2index[result[0]]] = result[1]\n",
    "\n",
    "# 使用HDBSCAN进行聚类，min_samples为每个点的最小邻居数，min_cluster_size为每个簇的最小点数，metric为距离度量方法，precomputed表示使用预计算的距离矩阵\n",
    "h = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=3, metric=\"precomputed\")\n",
    "hdb = h.fit(dist_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后，HDBSCAN 聚类就完成了。我们可以获取一些数据并显示其聚类结果。请注意，有些数据不会被分配到任何聚类中，这意味着它们是噪音，因为它们位于某些稀疏区域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 UMAP 进行聚类可视化\n",
    "我们已经使用 HDBSCAN 对数据进行了聚类，并获得了每个数据点的标签。不过，利用一些可视化技术，我们可以获得聚类的全貌，以便进行直观分析。现在，我们将使用 UMAP 对聚类进行可视化。UMAP 是一种用于降维的高效方法，它在保留高维数据结构的同时，将其投影到低维空间，以便进行可视化或进一步分析。有了它，我们就能在二维或三维空间中可视化原始高维数据，并清楚地看到聚类。 在这里，我们再次遍历数据点，获取原始数据的 ID 和文本，然后使用 ploty 将数据点与这些元信息绘制成图，并用不同的颜色代表不同的聚类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T07:56:05.388207Z",
     "iopub.status.busy": "2025-04-02T07:56:05.387914Z",
     "iopub.status.idle": "2025-04-02T07:56:15.269196Z",
     "shell.execute_reply": "2025-04-02T07:56:15.268329Z",
     "shell.execute_reply.started": "2025-04-02T07:56:05.388189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# 设置plotly的渲染器为notebook\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# 创建一个UMAP对象\n",
    "# 用于将高维数据降维到二维空间。UMAP的参数包括：\n",
    "# n_components=2：降维到二维。\n",
    "# random_state=42：设置随机种子以确保结果可复现。\n",
    "# n_neighbors=80和min_dist=0.1：控制UMAP的局部和全局结构保留程度\n",
    "umap = UMAP(n_components=2, random_state=42, n_neighbors=80, min_dist=0.1)\n",
    "\n",
    "\n",
    "df_umap = (\n",
    "    # 创建降维后的DataFrame\n",
    "    # 使用UMAP对embeddings（假设是高维嵌入向量）进行降维，并将结果存储在一个Pandas DataFrame中，列名为x和y。随后：\n",
    "    # 添加一列cluster，其值为HDBSCAN聚类结果的标签（hdb.labels_）。\n",
    "    # 过滤掉噪声点（cluster == \"-1\"）。\n",
    "    # 按照cluster列对数据进行排序。\n",
    "    pd.DataFrame(umap.fit_transform(np.array(embeddings)), columns=[\"x\", \"y\"])\n",
    "    .assign(cluster=lambda df: hdb.labels_.astype(str))\n",
    "    .query('cluster != \"-1\"')\n",
    "    .sort_values(by=\"cluster\")\n",
    ")\n",
    "# 从milvus中批量的查询数据\n",
    "iterator = collection.query_iterator(\n",
    "    batch_size=10, expr=\"id > 0\", output_fields=[\"id\", \"text\"]\n",
    ")\n",
    "\n",
    "ids = []\n",
    "texts = []\n",
    "# 查询到的数据存储到列表中\n",
    "while True:\n",
    "    batch = iterator.next()\n",
    "    if len(batch) == 0:\n",
    "        break\n",
    "    batch_ids = [data[\"id\"] for data in batch]\n",
    "    batch_texts = [data[\"text\"] for data in batch]\n",
    "    ids.extend(batch_ids)\n",
    "    texts.extend(batch_texts)\n",
    "\n",
    "show_texts = [texts[i] for i in df_umap.index]\n",
    "\n",
    "df_umap[\"hover_text\"] = show_texts\n",
    "fig = px.scatter(\n",
    "    df_umap, x=\"x\", y=\"y\", color=\"cluster\", hover_data={\"hover_text\": True}\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
